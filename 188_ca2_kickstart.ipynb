{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuerTang/CS88/blob/main/188_ca2_kickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35G_D38cbf0-"
      },
      "source": [
        "Make a copy of this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dp84Iyt6MTwE",
        "outputId": "d2dd1384-17f7-4a7b-8c0d-159a90066b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7f4Jp7nMc26"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from matplotlib import patches\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc0vunt56Oq1"
      },
      "source": [
        "Run these cells for some useful helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUKlxjhSMrj-"
      },
      "outputs": [],
      "source": [
        "def show_image(img, title=\"Image\", cmap=None):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    if cmap is None and len(img.shape) == 3:\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img_rgb)\n",
        "    else:\n",
        "        plt.imshow(img, cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y9tEg216gEG"
      },
      "source": [
        "Upload an image we will use (run the cell). You should be using an image with something red in it. We have some defaults you can download here: https://drive.google.com/drive/folders/1l2kCb40Wf7DVoQdPHKzsXzBTYmZJlTO7?usp=sharing\n",
        "\n",
        "I personally used ca2_0.png."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f0b49db764574800b0c700d66e35dc3b",
            "7874ab40f8f34d968abe50149c0f55ea",
            "cc6fbeaf463747b0b6a87a07ca47ae7f",
            "9a7fd4add2a743eeb10c974a5d24fa06",
            "f82864a0165c4145b55b6afc752e0db3",
            "78cb659a286e4a458ab336bacda4aa89"
          ]
        },
        "id": "g5_KErKJ6N8g",
        "outputId": "0697679d-6f43-4f4e-8e5a-5eaac688a69f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0b49db764574800b0c700d66e35dc3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value={}, accept='.jpg, .jpeg, .png', description='Upload Image')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a7fd4add2a743eeb10c974a5d24fa06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Process Image', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uploader = widgets.FileUpload(\n",
        "    accept='.jpg, .jpeg, .png',\n",
        "    multiple=False,\n",
        "    description='Upload Image'\n",
        ")\n",
        "\n",
        "def load_image(change=None):\n",
        "    if uploader.value and len(uploader.value) > 0:\n",
        "        file_info = next(iter(uploader.value.items()))\n",
        "        file_name, file_data = file_info\n",
        "\n",
        "        img_array = np.frombuffer(file_data['content'], dtype=np.uint8)\n",
        "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "        print(f\"Using uploaded image: {file_name}\")\n",
        "        return img\n",
        "    else:\n",
        "        print(\"Failed to upload image.\")\n",
        "\n",
        "display(uploader)\n",
        "\n",
        "process_button = widgets.Button(description=\"Process Image\")\n",
        "display(process_button)\n",
        "\n",
        "def on_process_button_clicked(b):\n",
        "    original_image = load_image()\n",
        "    if original_image is not None:\n",
        "        cv2.imwrite('temp_display.jpg', original_image)\n",
        "        display(Image('temp_display.jpg'))\n",
        "        print(\"Image loaded successfully! Shape:\", original_image.shape)\n",
        "    else:\n",
        "        print(\"Failed to load image.\")\n",
        "\n",
        "process_button.on_click(on_process_button_clicked)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwOYGqrV7c_b"
      },
      "source": [
        "Load our image and show it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "collapsed": true,
        "id": "IBw2aCga7aaY",
        "outputId": "4a8e93ea-69e0-4130-ad12-1de651fb7f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to upload image.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ea46794213f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-8d5593d16d53>\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(img, title, cmap)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mimg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "original_image = load_image()\n",
        "show_image(original_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeJBhn4N8nBR"
      },
      "source": [
        "Please implement this function. OpenCV uses BGR (Blue, Green, Red) by default. For the purposes of detection, we will be using HSV (Hue, Saturation, Value). Why might we want to do things in HSV space?\n",
        "\n",
        "Hint for implementation: look into cv2.cvtColor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV44Q2qrMyns"
      },
      "outputs": [],
      "source": [
        "def bgr_to_hsv(input_image):\n",
        "    \"\"\"\n",
        "    Convert an RGB image to HSV color space.\n",
        "\n",
        "    Parameters:\n",
        "        input_image (np.ndarray): Input RGB image (BGR format as used by OpenCV).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: HSV image.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdhAt_I8g9X"
      },
      "source": [
        "Use this function to display the different channels (hue, saturation, value). (Nothing to implement here)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdUp5ZMUM3Q5"
      },
      "outputs": [],
      "source": [
        "hsv_image = bgr_to_hsv(original_image)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(hsv_image[:,:,0], cmap='hsv')\n",
        "axes[0].set_title('Hue Channel')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(hsv_image[:,:,1], cmap='gray')\n",
        "axes[1].set_title('Saturation Channel')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(hsv_image[:,:,2], cmap='gray')\n",
        "axes[2].set_title('Value Channel')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMLAtCj58trF"
      },
      "source": [
        "In order to detect red in the image, we will create masks for red color in the HSV image. Two guiding questions:\n",
        "\n",
        "1. What channel should we be masking over?\n",
        "\n",
        "2. How many masks will we need? Why?\n",
        "\n",
        "Hint 1: One way to approach this is to implement a lower and upper mask to define a range. You could write something like mask = np.array([hue, sat, val]) for a single mask / bound.\n",
        "\n",
        "Hint 2: From your answer in (1), you will need to play around with some minimum and maximum values for the other channels as well.\n",
        "\n",
        "Hint 3: Once you have your upper and lower masks (i.e. you defined your range of values), look into cv2.inRange."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AtrexMUM5Ej"
      },
      "outputs": [],
      "source": [
        "def create_red_masks(hsv_image):\n",
        "    \"\"\"\n",
        "    Create a mask for red color in the HSV image.\n",
        "\n",
        "    Parameters:\n",
        "        hsv_image (np.ndarray): Input HSV image.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Binary mask where red pixels are white and others are black.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvfs-LBs8zzg"
      },
      "source": [
        "Visualize the two masks. Note that the upper red mask will not display much... why? (Nothing to implement here)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJsp27qBNIYK"
      },
      "outputs": [],
      "source": [
        "mask1, mask2 = create_red_masks(hsv_image)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "axes[0].imshow(mask1, cmap='gray')\n",
        "axes[0].set_title('Mask 1 (Lower Red)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(mask2, cmap='gray')\n",
        "axes[1].set_title('Mask 2 (Upper Red)')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7dFNcLC87Kt"
      },
      "source": [
        "From earlier, we have two separate masks to mask out the red from the image. Which binary operation can we use to combine them? Implement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsPP1SQCNJds"
      },
      "outputs": [],
      "source": [
        "def combine_masks(mask1, mask2):\n",
        "    \"\"\"\n",
        "    Combine two binary masks.\n",
        "\n",
        "    Parameters:\n",
        "        mask1 (np.ndarray): First binary mask.\n",
        "        mask2 (np.ndarray): Second binary mask.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Combined binary mask.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV_HLkk08_Og"
      },
      "source": [
        "Display the combined mask and any red images you detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4msZfYhNQxg"
      },
      "outputs": [],
      "source": [
        "combined_mask = combine_masks(mask1, mask2)\n",
        "\n",
        "show_image(combined_mask, \"Combined Red Mask\", cmap='gray')\n",
        "\n",
        "masked_image = cv2.bitwise_and(original_image, original_image, mask=combined_mask)\n",
        "show_image(masked_image, \"Red Objects Detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZmnptCa9FWO"
      },
      "source": [
        "Contours are curves that join all continuous points having the same color or intensity, which will be useful for us to identify the red object(s) in the image. There are two steps here:\n",
        "\n",
        "1. Extract the contours.\n",
        "2. From the contours, extract the largest contour.\n",
        "\n",
        "Implement!\n",
        "\n",
        "Hint 1: cv2.findContours\n",
        "\n",
        "Hint 2: max() takes a key argument! See cv2.contourArea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP93Z10aNSe5"
      },
      "outputs": [],
      "source": [
        "def extract_contour(mask):\n",
        "    \"\"\"\n",
        "    Extract largest contour from a binary mask.\n",
        "\n",
        "    Parameters:\n",
        "        mask (np.ndarray): Binary mask.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Largest contour found in the mask.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd1M1L719LWC"
      },
      "source": [
        "Display an outline of the contour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxcBnbX6Njb_"
      },
      "outputs": [],
      "source": [
        "largest_contour = extract_contour(combined_mask)\n",
        "\n",
        "contour_image = original_image.copy()\n",
        "cv2.drawContours(contour_image, [largest_contour], -1, (0, 255, 0), 3)\n",
        "show_image(contour_image, \"Largest Red Contour\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB0xYNbf9Nx-"
      },
      "source": [
        "Next, we want to calculate the centroid of a contour. To calculate the centroid of a contour, we need the image moments.\n",
        "\n",
        "Image moments capture the \"distribution\" of pixel intensities, and are defined as weighted aaverages of the image pixels' intensities. The zero-order moment m00 is the total mass/area. The first-order moments (m10, m01) are the center of mass coordinates.\n",
        "\n",
        "Mathematically,\n",
        "- m10 is the first-order moment w.r.t to the x-axis; represents the sum of all pixel intensities multiplied by their x-coordinates.\n",
        "- m01 is the first-order moment w.r.t to the y-axis; represents the sum of all pixel intensities multiplied by their y-coordinates.\n",
        "- m00 is the zero-th order moment; sum of all pixel intensities (\"mass\")\n",
        "\n",
        "Think about how we can use these image moments to find the centroid coordinates!\n",
        "\n",
        "Hint: cv2.moments(). The documentation on this is a bit sparse, but it returns a dictionary with the image moments. If you wanted i.e. the m00 moment, you would just index into the dictionary with that key, i.e. M[\"m00\"].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVQ1GjxcNoYV"
      },
      "outputs": [],
      "source": [
        "def calculate_centroid(contour):\n",
        "    \"\"\"\n",
        "    Calculate the centroid of a contour.\n",
        "\n",
        "    Parameters:\n",
        "        contour (np.ndarray): Contour points.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Centroid coordinates (x, y).\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sixdqlWZ9ek8"
      },
      "source": [
        "Display the centroid (in blue), with the contour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNwY3GKGOr4E"
      },
      "outputs": [],
      "source": [
        "centroid = calculate_centroid(largest_contour)\n",
        "\n",
        "centroid_image = contour_image.copy()\n",
        "cv2.circle(centroid_image, centroid, 10, (255, 0, 0), -1)\n",
        "cv2.putText(centroid_image, f\"{centroid}\", (centroid[0]-50, centroid[1]-20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "show_image(centroid_image, \"Contour with Centroid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR05GMXI9i6w"
      },
      "source": [
        "We have finished all the helper functions. Now put it all together to create the pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-J6pnlAOxJj"
      },
      "outputs": [],
      "source": [
        "def detect_red_blob(image):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXrOtp7o9rZu"
      },
      "source": [
        "Putting it all together..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr3F-x7DO1Nv"
      },
      "outputs": [],
      "source": [
        "red_blob_centroid = detect_red_blob(original_image)\n",
        "\n",
        "result_image = original_image.copy()\n",
        "\n",
        "hsv_image = bgr_to_hsv(original_image)\n",
        "mask1, mask2 = create_red_masks(hsv_image)\n",
        "mask = combine_masks(mask1, mask2)\n",
        "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "cv2.drawContours(result_image, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "if contours:\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    cv2.drawContours(result_image, [largest_contour], -1, (255, 0, 0), 3)\n",
        "\n",
        "    cv2.circle(result_image, red_blob_centroid, 10, (0, 0, 255), -1)\n",
        "    cv2.putText(result_image, f\"{red_blob_centroid}\",\n",
        "                (red_blob_centroid[0]-50, red_blob_centroid[1]-20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "show_image(result_image, \"Red Blob Detection\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7874ab40f8f34d968abe50149c0f55ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78cb659a286e4a458ab336bacda4aa89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9a7fd4add2a743eeb10c974a5d24fa06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Process Image",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f82864a0165c4145b55b6afc752e0db3",
            "style": "IPY_MODEL_78cb659a286e4a458ab336bacda4aa89",
            "tooltip": ""
          }
        },
        "cc6fbeaf463747b0b6a87a07ca47ae7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f0b49db764574800b0c700d66e35dc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FileUploadModel",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".jpg, .jpeg, .png",
            "button_style": "",
            "data": [],
            "description": "Upload Image",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_7874ab40f8f34d968abe50149c0f55ea",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_cc6fbeaf463747b0b6a87a07ca47ae7f"
          }
        },
        "f82864a0165c4145b55b6afc752e0db3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
